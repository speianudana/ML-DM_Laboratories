{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.3. Use the dataset Data1.csv to implement the list of classification models below in order to predict whether a tumor is malign or beginning. The dependent variable in this dataset is Class, it is equal to 2 if the tumor is benign and 4 if it is malign. The remaining columns are features that describe different characteristics of each tumor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data1.csv')\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now will split the dataset into the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Logistic Regression library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Logistic Regression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model on the data, storing the information learned from the data\n",
    "Model is learning the relationship between digits (x_train) and labels (y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict labels for new data. Uses the information the model learned during the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.predict(x_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict for Multiple Observations at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 4, 2, 2, 2, 4, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on entire test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the accuracy of the model using the score method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.62 %\n"
     ]
    }
   ],
   "source": [
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(\"Accuracy: {:.2f} %\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84  3]\n",
      " [ 3 47]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results above the accuracy of the model is not quite good - 95.62%. There were 6 values out of 137 that were not predicted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using K-fold cross-validation method (cv = 10) will ensure that the accuracy score calculated only on one test set was not just a lucky occurence. Will print the nest accuracy score and the standard deviation  of the score computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.70 %\n",
      "Standard Deviation: 1.97 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.94545455, 0.96363636, 0.96363636, 1.        , 0.94545455,\n",
       "       1.        , 0.96296296, 0.96296296, 0.98148148, 0.94444444])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "logisticRegr_accuracies = cross_val_score(estimator = logisticRegr, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(logisticRegr_accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(logisticRegr_accuracies.std()*100))\n",
    "logisticRegr_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean accurracy for 10 test sets is 96.7% that is not much bigger that the accuracy of the model calculated on only one train data set (95.62%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Decision Tree Model using Scikit-learn. Import Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Decision Tree classifer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier( random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Decision Tree Classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = dtc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the response for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's estimate, how accurately the classifier or model can predict whether a tumor is malign or bening. Accuracy can be computed by comparing actual test set values and predicted values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.70 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f} %\".format(metrics.accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80  7]\n",
      " [ 3 47]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this model has a big accuracy that means it is good to use for predicting whether a tumor is malign or benign. The confusion matrix also shows that only 10 out of 137 objects are not predicted as they had to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using K-fold cross-validation method (cv = 10) will ensure that the accuracy score calculated only on one test set was not just a lucky occurence. Will print the nest accuracy score and the standard deviation  of the score computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.59 %\n",
      "Standard Deviation: 2.21 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92727273, 0.90909091, 0.92727273, 0.96363636, 0.94545455,\n",
       "       0.92727273, 0.90740741, 0.92592593, 0.98148148, 0.94444444])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "dtc_accuracies = cross_val_score(estimator = dtc, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(dtc_accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(dtc_accuracies.std()*100))\n",
    "dtc_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean accuracy calculated for 10 subsets of data is bigger with 0.89% that the accuracy of the model calculated on only one test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier (with nb_trees = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Random Forest Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Gaussian Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier(n_estimators=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the training sets y_pred=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the response for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, check the accuracy using actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.43 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f} %\".format(metrics.accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  4]\n",
      " [ 5 45]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the accuracy of the model is pretty high - 96,35%. There are only 5 values that were not predicted to the correct group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using K-fold cross-validation method (cv = 10) will ensure that the accuracy score calculated only on one test set was not just a lucky occurence. Will print the nest accuracy score and the standard deviation  of the score computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.08 %\n",
      "Standard Deviation: 2.02 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.94545455, 0.94545455, 0.98181818, 0.96363636, 0.94545455,\n",
       "       1.        , 0.98148148, 0.96296296, 1.        , 0.98148148])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "rfc_accuracies = cross_val_score(estimator = rfc, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(rfc_accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(rfc_accuracies.std()*100))\n",
    "rfc_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can observe that the mean value of the accuracy for the model calculated on 10 test datasets (96.15%) is bigger than the value of the accuracy on the model calculated on only one test dataset (95.62%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. K- Nearest Neighbors (K-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the KNeighborsClassifier library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the object of KNeighborsClassifier type with number of neighbors =3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the KNeighbors Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the response for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, check the accuracy using actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.08 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f} %\".format(metrics.accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  2]\n",
      " [ 2 48]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that this model is better that the previous ones. This has 97.08% of accuracy and only 4 values out of 137 are predicted wrongly. For sure is one of the best candidates for the best models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using K-fold cross-validation method (cv = 10) will ensure that the accuracy score calculated only on one test set was not just a lucky occurence. Will print the nest accuracy score and the standard deviation  of the score computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.34 %\n",
      "Standard Deviation: 2.44 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.90909091, 0.94545455, 0.98181818, 0.98181818, 0.94545455,\n",
       "       1.        , 0.96296296, 0.96296296, 0.98148148, 0.96296296])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "neigh_accuracies = cross_val_score(estimator = neigh, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(neigh_accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(neigh_accuracies.std()*100))\n",
    "neigh_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the accuracy for the model calculated on only one test dataset is bigger than the mean accuracy for the model calculated on 10 smaller test data sets with 0.74%. Here we can say that there was a little lucky occurences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the GaussianNB library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the GaussianNB object and train it on the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions on the testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing actual response values (y_test) with predicted response values (y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy: {:.2f}%\".format(metrics.accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80  7]\n",
      " [ 0 50]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a pretty good accuracy- 94.89%. There are only 7 values that were predicted wrongly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using K-fold cross-validation method (cv = 10) will ensure that the accuracy score calculated only on one test set was not just a lucky occurence. Will print the nest accuracy score and the standard deviation  of the score computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.16 %\n",
      "Standard Deviation: 1.91 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92727273, 0.96363636, 0.96363636, 0.96363636, 0.96363636,\n",
       "       0.96363636, 0.98148148, 0.94444444, 1.        , 0.94444444])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "gnb_accuracies = cross_val_score(estimator = gnb, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(gnb_accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(gnb_accuracies.std()*100))\n",
    "gnb_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be observed that the accuracy score of the model calculated on only one test set is smaller that the accuracy mean calculated on 10 smaller data sets. (94.89% < 96.16%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the SVC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(random_state=0)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions and compare the results by displaying the predicted values of y next to the test values of y in a two-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 2, 2,\n",
       "       4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2,\n",
       "       2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4,\n",
       "       4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 2, 2,\n",
       "       4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2,\n",
       "       4, 2, 2, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and print the Confusion Matrix and the accuracy score of the model and interpret the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82  5]\n",
      " [ 1 49]]\n",
      "SVC model accuracy: 95.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"SVC model accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that this is a good model with an accuracy of 95.62%. There are 6 values that were not predicted correctly.\n",
    "\n",
    "Using K-fold cross-validation method (cv = 10) will ensure that the accuracy score calculated only on one test set was not just a lucky occurence. Will print the nest accuracy score and the standard deviation  of the score computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.53 %\n",
      "Standard Deviation: 1.91 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92727273, 0.96363636, 0.96363636, 0.98181818, 0.96363636,\n",
       "       0.96363636, 0.98148148, 0.96296296, 1.        , 0.94444444])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "svm_accuracies = cross_val_score(estimator = clf, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(svm_accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(svm_accuracies.std()*100))\n",
    "svm_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the accuracy score calculated for a only one test set is smaller with 0.92% than the accuracy mean calculatd for 10 test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.4. Choose the best performing model based on the results from performing the k-fold cross-validation. Discuss your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Logistic Regression model: 96.70 %, Std: 1.97.\n",
      "Mean accuracy for Decision Tree Classifier model: 93.59%, Std: 2.21.\n",
      "Mean accuracy for Random Forest Classifier with 10 nb_trees: 97.08 %, Std: 2.02.\n",
      "Mean accuracy for K-Nearest Neighbors: 96.34 %, Std: 2.44.\n",
      "Mean accuracy for Naive Bayes: 96.16 %, Std: 1.91.\n",
      "Mean accuracy for Support Vector Machine: 96.53 %, Std: 1.91.\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for Logistic Regression model: {:.2f} %, Std: {:.2f}.\".format(logisticRegr_accuracies.mean()*100, logisticRegr_accuracies.std()*100))\n",
    "print(\"Mean accuracy for Decision Tree Classifier model: {:.2f}%, Std: {:.2f}.\".format(dtc_accuracies.mean()*100, dtc_accuracies.std()*100))\n",
    "print(\"Mean accuracy for Random Forest Classifier with 10 nb_trees: {:.2f} %, Std: {:.2f}.\".format(rfc_accuracies.mean()*100, rfc_accuracies.std()*100))\n",
    "print(\"Mean accuracy for K-Nearest Neighbors: {:.2f} %, Std: {:.2f}.\".format(neigh_accuracies.mean()*100, neigh_accuracies.std()*100))\n",
    "print(\"Mean accuracy for Naive Bayes: {:.2f} %, Std: {:.2f}.\".format(gnb_accuracies.mean()*100, gnb_accuracies.std()*100))\n",
    "print(\"Mean accuracy for Support Vector Machine: {:.2f} %, Std: {:.2f}.\".format(svm_accuracies.mean()*100, svm_accuracies.std()*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the best mean accuracy is for Random Forest Classifier model.  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
